{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# STRING DB project \n",
    "\n",
    "## layout of the data \n",
    "- the data will be converted into a SIF format. \n",
    "- SIF requires 3 things \n",
    "    - Node A\n",
    "    - Interactions\n",
    "    - Node B\n",
    "    - Score\n",
    "\n",
    "The types of interactions that the SIF handles in cyotscape is \n",
    "  pp .................. protein - protein interaction <-- Using this one\n",
    "  pd .................. protein -> DNA\n",
    "  pr .................. protein -> reaction\n",
    "  rc .................. reaction -> compound\n",
    "  cr .................. compound -> reaction\n",
    "  gl .................. genetic lethal relationship\n",
    "  pm .................. protein-metabolite interaction\n",
    "  mp .................. metabolite-protein interaction\n",
    "\n",
    "since our STRING  DATABASE is protein protein intearctions there pp will be the selected interaction type\n",
    "\n",
    "## Downsides\n",
    "---\n",
    "The main disadvantage is that this format does not include any layout information, forcing Cytoscape to re-compute a new layout of the network each time it is loaded.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "source": [
    "class StringDB:\n",
    "    def __init__(self, fname):\n",
    "\n",
    "        # automatically loading in database when instantiating StringDB object\n",
    "        self.fname = fname\n",
    "        db = self._load_string_data(fname)\n",
    "        self.db = db\n",
    "\n",
    "\n",
    "    def _load_string_data(self, f_path: str) -> pd.DataFrame:\n",
    "        \"\"\" Loads in the STRING database and converts it into a pandas dataframe object\"\"\"\n",
    "        string_df = pd.read_csv(f_path, sep=\"\\t\")\n",
    "        string_df.columns = [\"gene1\", \"gene2\", \"score\"]\n",
    "        return string_df\n",
    "\n",
    "\n",
    "    def _cross_ref(self, locus: str, target: list, reference: list) -> None:\n",
    "        \"\"\"Cross references matches with initial inputs to see which pairs\n",
    "        were not found\"\"\"\n",
    "\n",
    "        target_set = set(target)\n",
    "        ref_set = set(reference)\n",
    "\n",
    "        \n",
    "        missing_set = ref_set - target_set\n",
    "        for missing in missing_set:\n",
    "            print(\"WARNING: Not found {} - {}\".format(locus, missing))\n",
    "    \n",
    "\n",
    "    def _to_adjacency_dict(self, selected_pairs):\n",
    "        \"\"\" converts the selected pairs into a adjacency dict\"\"\"\n",
    "\n",
    "        main_result = {} # stores locus and all genes and scores\n",
    "        gene_score = {} # --> stores gene and score\n",
    "        for idx in range(len(selected_pairs.index.tolist())):\n",
    "            data = selected_pairs.iloc[idx]\n",
    "            gene, score = (data[\"gene2\"], data[\"score\"])\n",
    "            gene_score[gene] = score\n",
    "\n",
    "        main_result[locus] = gene_score\n",
    "        return main_result\n",
    "    \n",
    "\n",
    "    def find_pairs(self, locus, genes):\n",
    "        \"\"\" Attempts to find all pairs with a given locus.\n",
    "        \n",
    "        arguments\n",
    "        ----------\n",
    "        locus: str\n",
    "            Main gene that will be used to compare all genes\n",
    "        genes: list, np.array\n",
    "            An array genes names\n",
    "\n",
    "        returns\n",
    "        -------\n",
    "        dict\n",
    "            A nested dictionary containing the locus as the main key and the sub dictionary \n",
    "            containing the queryed gene along with its score. NaN will be placed if gene\n",
    "            pairs are not found\n",
    "        \n",
    "        \"\"\"\n",
    "        # data type checking\n",
    "        if not isinstance(locus, str):\n",
    "            raise TypeError(\"locus must be a string. you have provided {}\". type(locus))\n",
    "        if not isinstance(genes, list) and not isinstance(genes, np.ndarray):\n",
    "            raise TypeError(\"'genes' data must be a list or numpy array, you have provided {}\".format(type(genes)))\n",
    "        # query searches all given genes with one locus\n",
    "        # -- this process is vectorized does not use a for loop to find every single match\n",
    "        # -- pairs that are NOT found will not be included in the results\n",
    "        # -- -- We use the _cross_ref() function to let the user know which pairs where not found\n",
    "        query = self.db.loc[(self.db[\"gene1\"] == locus) & (self.db[\"gene2\"].isin(genes))] \n",
    "        selected_genes = query[\"gene2\"].values.tolist()\n",
    "        \n",
    "        # checking for missing pairs\n",
    "        self._cross_ref(locus, selected_genes, genes)\n",
    "        \n",
    "        # return results\n",
    "        results = self._to_adjacency_dict(query)\n",
    "        return results"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "source": [
    "path = \"../Data/STRING.txt\"\n",
    "string_db = StringDB(path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "source": [
    "locus = \"ARF5\"\n",
    "genes = np.array(\"DYRK4 PPP5C MAP4K5 RALBP1 PKP2 NOGENE\".split())\n",
    "\n",
    "\n",
    "string_db.find_pairs(locus=locus, genes=genes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "WARNING: Not found ARF5 - NOGENE\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'ARF5': {'DYRK4': 0.166,\n",
       "  'PPP5C': 0.254968,\n",
       "  'MAP4K5': 0.157276,\n",
       "  'RALBP1': 0.156,\n",
       "  'PKP2': 0.16021}}"
      ]
     },
     "metadata": {},
     "execution_count": 167
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "def save_to_sif()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('CPBS': conda)"
  },
  "interpreter": {
   "hash": "1576e85106ece8c10c2f99e1492bb7e52cf40dee39c5ec10f8bdd823877a9148"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}